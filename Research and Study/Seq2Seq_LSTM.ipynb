{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://github.com/MahaQ3/A_Conversational_Chatbot_model/blob/main/chatbot.ipynb\n",
        "# Reference: Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]Retrieved: https://nlp.stanford.edu/projects/glove/"
      ],
      "metadata": {
        "id": "vuXrIlY2c4no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InaZfW3HHzr2",
        "outputId": "cdb44680-d2e0-426c-a420-6245c5894aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to improve encoding below\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from IPython.core.display import display, HTML\n",
        "from tensorflow.keras.layers import TimeDistributed, Dense\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Activation, dot, concatenate\n",
        "from google.colab import drive\n",
        "# Reference: https://github.com/MahaQ3/A_Conversational_Chatbot_model/blob/main/chatbot.ipynb\n",
        "# Reference: Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation. [pdf] [bib]Retrieved: https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "\n",
        "INPUT_LENGTH = 20\n",
        "OUTPUT_LENGTH = 20\n",
        "\n",
        "\n",
        "txt=open('/content/drive/MyDrive/movie-corpus/movie_lines_pre_processed_for_test.tsv','r').readlines()\n",
        "# Clean data\n",
        "\n",
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|]\", \"\", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "# Print the first few lines of the text data after cleaning\n",
        "for i in range(5):\n",
        "  print(f\"Original Text: {txt[i]}\")\n",
        "  print(f\"Cleaned Text: {clean_text(txt[i])}\")\n",
        "  print(\"---\")\n",
        "\n",
        "\n",
        "#split the data to questions and answers\n",
        "questions=[]\n",
        "answers=[]\n",
        "for index,sent in enumerate(txt):\n",
        "  if index%2==0:\n",
        "    questions.append(sent)\n",
        "  else:\n",
        "    answers.append(sent)\n",
        "\n",
        "\n",
        "print(f\"Number of questions: {len(questions)}\")\n",
        "print(f\"Number of answers: {len(answers)}\")\n",
        "\n",
        "if len(questions) > 0 and len(answers) > 0:\n",
        "  print(\"The code worked successfully!\")\n",
        "  print(\"Questions and answers have been split.\")\n",
        "else:\n",
        "  print(\"The code may not have worked correctly.\")\n",
        "  print(\"Questions or answers are empty.\")\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "#choosing number of samples\n",
        "num_samples = 30000  # Number of samples to train on.\n",
        "\n",
        "# Initialize short_questions and short_answers by slicing the original lists:\n",
        "short_questions = questions[:num_samples] # Slicing the 'questions' list\n",
        "short_answers = answers[:num_samples]   # Slicing the 'answers' list\n",
        "\n",
        "#tokenizing the qns and answers\n",
        "short_questions_tok = [nltk.word_tokenize(sent) for sent in short_questions]\n",
        "short_answers_tok = [nltk.word_tokenize(sent) for sent in short_answers]\n",
        "\n",
        "# training data & validation data\n",
        "\n",
        "\n",
        "#train-validation split\n",
        "data_size = len(short_questions_tok)\n",
        "\n",
        "# We will use the first 0-80th %-tile (80%) of data for the training\n",
        "training_input  = short_questions_tok[:round(data_size*(80/100))]\n",
        "training_input  = [tr_input[::-1] for tr_input in training_input] #reverseing input seq for better performance\n",
        "training_output = short_answers_tok[:round(data_size*(80/100))]\n",
        "\n",
        "# We will use the remaining for validation\n",
        "validation_input = short_questions_tok[round(data_size*(80/100)):]\n",
        "validation_input  = [val_input[::-1] for val_input in validation_input] #reverseing input seq for better performance\n",
        "validation_output = short_answers_tok[round(data_size*(80/100)):]\n",
        "\n",
        "print('training size', len(training_input))\n",
        "print('validation size', len(validation_input))\n",
        "# Word en/decoding dictionaries\n",
        "\n",
        "\n",
        "# Create a dictionary for the frequency of the vocabulary\n",
        "vocab = {}\n",
        "for question in short_questions_tok:\n",
        "    for word in question:\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n",
        "for answer in short_answers_tok:\n",
        "    for word in answer:\n",
        "        if word not in vocab:\n",
        "            vocab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG1092AJBvpi",
        "outputId": "e3fe4091-db9c-471a-9854-7c205afdd4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: L49\tu0\tm0\tDid you change your hair?\tNo.\tchange hair\t1\n",
            "\n",
            "Cleaned Text: l49 u0 m0 did you change your hair? no. change hair 1\n",
            "---\n",
            "Original Text: L59\tu9\tm0\tI missed you.\tIt says here you exposed yourself to a group of freshmen girls.\tmiss\t0\n",
            "\n",
            "Cleaned Text: l59 u9 m0 i missed you. it says here you exposed yourself to a group of freshmen girls. miss 0\n",
            "---\n",
            "Original Text: L60\tu8\tm0\tIt says here you exposed yourself to a group of freshmen girls.\tIt was a bratwurst. I was eating lunch.\tsay expose group freshman girl\t0\n",
            "\n",
            "Cleaned Text: l60 u8 m0 it says here you exposed yourself to a group of freshmen girls. it was a bratwurst. i was eating lunch. say expose group freshman girl 0\n",
            "---\n",
            "Original Text: L61\tu9\tm0\tIt was a bratwurst. I was eating lunch.\tWith the teeth of your zipper?\tbratwurst eat lunch\t0\n",
            "\n",
            "Cleaned Text: l61 u9 m0 it was a bratwurst. i was eating lunch. with the teeth of your zipper? bratwurst eat lunch 0\n",
            "---\n",
            "Original Text: L63\tu7\tm0\tYou the new guy?\tSo they tell me...\tnew guy\t1\n",
            "\n",
            "Cleaned Text: l63 u7 m0 you the new guy? so they tell me... new guy 1\n",
            "---\n",
            "Number of questions: 15000\n",
            "Number of answers: 15000\n",
            "The code worked successfully!\n",
            "Questions and answers have been split.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training size 12000\n",
            "validation size 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "30d25056e8f62453bcde0a16c8a7933275f431c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvyaR4YqAkGK",
        "outputId": "90dfebc8-af28-4f34-ff53-37b66dcb0513"
      },
      "source": [
        "# Remove rare words from the vocabulary.\n",
        "# We will aim to replace fewer than 5% of words with <UNK>\n",
        "# You will see this ratio soon.\n",
        "threshold = 15\n",
        "count = 0\n",
        "for k,v in vocab.items():\n",
        "    if v >= threshold:\n",
        "        count += 1\n",
        "\n",
        "print(\"Size of total vocab:\", len(vocab))\n",
        "print(\"Size of vocab we will use:\", count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of total vocab: 40808\n",
            "Size of vocab we will use: 2795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d62a629773e34bb7bc1a12508cce820c0e47962d",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae14911-2de7-4419-9806-c65c78f17628",
        "id": "f9aN8tMiAt6Y"
      },
      "source": [
        "#we will create dictionaries to provide a unique integer for each word.\n",
        "WORD_CODE_START = 1\n",
        "WORD_CODE_END=2\n",
        "WORD_CODE_PADDING = 0\n",
        "\n",
        "word_num  = 3 #number 1 & 2  are left for WORD_CODE_START & WORD_CODE_END for model decoder later\n",
        "encoding = {'START': 1, 'END':2}\n",
        "decoding = {1:  'START',2: 'END'}\n",
        "for word, count in vocab.items():\n",
        "    if count >= threshold: #get vocabularies that appear above threshold count\n",
        "        encoding[word] = word_num\n",
        "        decoding[word_num ] = word\n",
        "        word_num += 1\n",
        "\n",
        "print(\"No. of vocab used:\", word_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of vocab used: 2798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "de2e46d3826def6b6c94a9827c32118d555fae2e",
        "id": "k0qy7qVKA2tK"
      },
      "source": [
        "#include unknown token for words not in dictionary\n",
        "decoding[len(encoding)+3] = '<UNK>'\n",
        "encoding['<UNK>'] = len(encoding)+3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "bccd51e8730e7c3da1234af9480da767f400c230",
        "collapsed": true,
        "id": "UE1PJO2PA98x"
      },
      "source": [
        "dict_size = word_num+3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4GgYyo_BCLu"
      },
      "source": [
        "\n",
        "np.save('word2id.npy',encoding)\n",
        "np.save('id2word.npy',decoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(encoding, data, vector_size=20):\n",
        "    \"\"\"\n",
        "    :param encoding: encoding dict built by build_word_encoding()\n",
        "    :param data: list of strings\n",
        "    :param vector_size: size of each encoded vector\n",
        "    \"\"\"\n",
        "    for i in range(len(data)):\n",
        "        for j in range(min(len(data[i]), vector_size)):\n",
        "            try:\n",
        "                np.zeros(shape=(len(data), vector_size))[i][j] = encoding[data[i][j]]\n",
        "            except:\n",
        "                np.zeros(shape=(len(data), vector_size))[i][j] = encoding['<UNK>']\n",
        "    return np.zeros(shape=(len(data), vector_size))"
      ],
      "metadata": {
        "id": "0AAwnq4nBKnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n"
      ],
      "metadata": {
        "id": "xS82w6FaB-sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input layers with unique names\n",
        "encoder_input = Input(shape=(INPUT_LENGTH,), name='encoder_input')\n",
        "decoder_input = Input(shape=(INPUT_LENGTH,), name='decoder_input')"
      ],
      "metadata": {
        "id": "KvIHXLvaCCd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/glove.twitter.27B.25d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))\n",
        "# create a weight matrix for words in training docs\n",
        "embedding_matrix = np.zeros((dict_size, 25))\n",
        "for word, i in encoding.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector\n",
        "\n",
        "embed_layer = Embedding(input_dim=dict_size, output_dim=25,input_length=INPUT_LENGTH, trainable=True, mask_zero=True)\n",
        "embed_layer.build((None,))\n",
        "embed_layer.set_weights([embedding_matrix])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4fcdc3-2606-4abf-d873-e482d282fd9d",
        "id": "cL4QEI67CIiN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1193514 word vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = embed_layer(encoder_input)\n",
        "encoder = LSTM(512, return_sequences=True, unroll=True)(encoder)\n",
        "encoder_last = encoder[:, -1, :]\n",
        "\n",
        "print('encoder', encoder)\n",
        "print('encoder_last', encoder_last)\n",
        "\n",
        "# Use the existing decoder_input\n",
        "decoder_embedding = embed_layer(decoder_input)\n",
        "decoder = LSTM(512, return_sequences=True, unroll=True)(decoder_embedding, initial_state=[encoder_last, encoder_last])\n",
        "\n",
        "print('decoder', decoder)\n",
        "\n",
        "# For the plain Sequence-to-Sequence, we produced the output from directly from decoder\n",
        "# output = TimeDistributed(Dense(output_dict_size,\n",
        "# activation=\"softmax\"))(decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5e7ad1-6b3c-4afa-a727-1f7855575632",
        "id": "GI8LXF9UCN-u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder <KerasTensor shape=(None, 20, 512), dtype=float32, sparse=False, name=keras_tensor_2>\n",
            "encoder_last <KerasTensor shape=(None, 512), dtype=float32, sparse=False, name=keras_tensor_3>\n",
            "decoder <KerasTensor shape=(None, 20, 512), dtype=float32, sparse=False, name=keras_tensor_6>\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install keras-self-attention\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import initializers, activations, regularizers, constraints\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, units, activation='tanh',\n",
        "                 use_bias=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 bias_initializer='zeros',\n",
        "                 kernel_regularizer=None,\n",
        "                 bias_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 bias_constraint=None,\n",
        "                 **kwargs):\n",
        "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
        "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pK3rR0txk6qs",
        "outputId": "bada07e5-8223-46f9-bc06-ce881ea071c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-self-attention) (1.26.4)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=6b302204b5564816850523557e63f1ac80c5526e6ae55a4b88f41aba8af26932\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        decoder_hidden_state, encoder_outputs = inputs\n",
        "\n",
        "        # Expand dims to enable broadcasting\n",
        "        decoder_hidden_state_time = tf.expand_dims(decoder_hidden_state, 1)\n",
        "\n",
        "        # Calculate score using dot-product attention\n",
        "        score = self.V(tf.tanh(\n",
        "            self.W1(decoder_hidden_state_time) + self.W2(encoder_outputs)))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # Calculate context vector\n",
        "        context_vector = attention_weights * encoder_outputs\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        # Concatenate context vector and decoder hidden state\n",
        "        output = tf.keras.layers.concatenate([context_vector, decoder_hidden_state], axis=-1) #  concatenate on the last axis\n",
        "\n",
        "        # # Apply TimeDistributed Dense layer to the output (optional)\n",
        "        # output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.units, activation=\"tanh\"))(output)\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "96eTMkKyCV69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        decoder_hidden_state, encoder_outputs = inputs\n",
        "\n",
        "        # Expand dims to enable broadcasting\n",
        "        decoder_hidden_state_time = tf.expand_dims(decoder_hidden_state, 1)\n",
        "\n",
        "        # Calculate score using dot-product attention\n",
        "        score = self.V(tf.tanh(\n",
        "            self.W1(decoder_hidden_state_time) + self.W2(encoder_outputs)))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # Calculate context vector\n",
        "        context_vector = attention_weights * encoder_outputs\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        # Concatenate context vector and decoder hidden state\n",
        "        output = tf.keras.layers.concatenate([context_vector, decoder_hidden_state], axis=-1) #  concatenate on the last axis\n",
        "\n",
        "        # # Apply TimeDistributed Dense layer to the output (optional)\n",
        "        # output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.units, activation=\"tanh\"))(output)\n",
        "        return output\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Alternatively if you have a decoding dictionary\n",
        "# Replace `decoding` with your decoding dictionary\n",
        "target_vocabulary = list(decoding.keys())\n",
        "\n",
        "# Calculate the output vocabulary size based on your target vocabulary\n",
        "output_dict_size = len(target_vocabulary)  # or however you define the output vocabulary size\n",
        "\n",
        "# Define the output layer\n",
        "output = tf.keras.layers.TimeDistributed(\n",
        "    tf.keras.layers.Dense(output_dict_size, activation=\"softmax\")\n",
        ")(decoder)  # or your attention mechanism output\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Model(inputs=[encoder_input, decoder_input], outputs=[output])\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "THr2SxmZmLZn",
        "outputId": "2be4cd3a-7d88-41f7-ad32-63bb7c37e06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_input             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m25\u001b[0m)         │         \u001b[38;5;34m70,025\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                           │                        │                │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m1,101,824\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │      \u001b[38;5;34m1,101,824\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                           │                        │                │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m2798\u001b[0m)       │      \u001b[38;5;34m1,435,374\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ encoder_input             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">70,025</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                           │                        │                │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,824</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,101,824</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                           │                        │                │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2798</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,435,374</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,709,047\u001b[0m (14.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,709,047</span> (14.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,709,047\u001b[0m (14.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,709,047</span> (14.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_batch(input_data, output_text_data, batch_size):\n",
        "    while True:\n",
        "        for j in range(0, len(input_data), batch_size):\n",
        "            # Pad both encoder and decoder input data to INPUT_LENGTH (20)\n",
        "            encoder_input_data = pad_sequences(input_data[j:j + batch_size], INPUT_LENGTH).astype('float32')\n",
        "            decoder_input_data = pad_sequences(output_text_data[j:j + batch_size], INPUT_LENGTH).astype('float32')\n",
        "            decoder_target_data = np.zeros((len(output_text_data[j:j + batch_size]), INPUT_LENGTH, dict_size), # Change target data shape to match\n",
        "                                          dtype=\"float32\")\n",
        "\n",
        "            for i, (input_text, target_text) in enumerate(zip(output_text_data[j:j + batch_size], output_text_data[j:j + batch_size])):\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t > 0:\n",
        "                        if word in encoding and encoding[word] < dict_size:\n",
        "                            decoder_target_data[i, t - 1, encoding[word]] = 1\n",
        "                        else:\n",
        "                            if '<UNK>' in encoding and encoding['<UNK>'] < dict_size:\n",
        "                                decoder_target_data[i, t - 1, encoding['<UNK>']] = 1\n",
        "                            else:\n",
        "                                pass\n",
        "\n",
        "            yield (encoder_input_data, decoder_input_data), decoder_target_data\n",
        "\n",
        "INPUT_LENGTH = 20\n",
        "#OUTPUT_LENGTH = 22 # Remove or adjust if needed but keep consistent\n",
        "dict_size = 1000\n",
        "\n",
        "# Define output types for the generator\n",
        "output_types = ((tf.float32, tf.float32), tf.float32)  # Tuple of types for (encoder_input, decoder_input), decoder_target\n",
        "\n",
        "# Define output shapes for the generator, use INPUT_LENGTH consistently\n",
        "output_shapes = (\n",
        "    (tf.TensorShape([None, INPUT_LENGTH]), tf.TensorShape([None, INPUT_LENGTH])),  # Shapes for encoder_input, decoder_input\n",
        "    tf.TensorShape([None, INPUT_LENGTH, dict_size])  # Shape for decoder_target\n",
        ")\n",
        "\n",
        "# Create the dataset using from_generator with output_types and output_shapes\n",
        "train_gen = tf.data.Dataset.from_generator(\n",
        "    lambda: generate_batch(encoded_training_input, encoded_training_output, 128),\n",
        "    output_types=output_types,\n",
        "    output_shapes=output_shapes\n",
        ").prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "a1Iv_WbSJblo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def generate_batch(input_data, output_text_data, batch_size):\n",
        "    while True:\n",
        "        for j in range(0, len(input_data), batch_size):\n",
        "            # Pad both encoder and decoder input data to INPUT_LENGTH (20)\n",
        "            encoder_input_data = pad_sequences(input_data[j:j + batch_size], INPUT_LENGTH).astype('float32')\n",
        "            decoder_input_data = pad_sequences(output_text_data[j:j + batch_size], INPUT_LENGTH).astype('float32')\n",
        "            decoder_target_data = np.zeros((len(output_text_data[j:j + batch_size]), INPUT_LENGTH, dict_size), # Change target data shape to match\n",
        "                                          dtype=\"float32\")\n",
        "\n",
        "            for i, (input_text, target_text) in enumerate(zip(output_text_data[j:j + batch_size], output_text_data[j:j + batch_size])):\n",
        "                for t, word in enumerate(target_text):\n",
        "                    if t > 0:\n",
        "                        if word in encoding and encoding[word] < dict_size:\n",
        "                            decoder_target_data[i, t - 1, encoding[word]] = 1\n",
        "                        else:\n",
        "                            if '<UNK>' in encoding and encoding['<UNK>'] < dict_size:\n",
        "                                decoder_target_data[i, t - 1, encoding['<UNK>']] = 1\n",
        "                            else:\n",
        "                                pass\n",
        "\n",
        "            # Create a mask manually and convert to tf.Tensor\n",
        "            mask = tf.convert_to_tensor(encoder_input_data != 0, dtype=tf.float32)\n",
        "\n",
        "            yield (encoder_input_data, decoder_input_data, mask), decoder_target_data # Yield the mask as part of the input data\n",
        "\n",
        "\n",
        "# Update the model's input to include the mask\n",
        "encoder_input = tf.keras.Input(shape=(INPUT_LENGTH,), name='encoder_input')\n",
        "decoder_input = tf.keras.Input(shape=(INPUT_LENGTH,), name='decoder_input')\n",
        "mask_input = tf.keras.Input(shape=(INPUT_LENGTH,), name='mask_input')  # Add mask input\n",
        "\n",
        "# Update the model's inputs to include the mask\n",
        "model = tf.keras.Model(inputs=[encoder_input, decoder_input, mask_input], outputs=[output])  # Include mask in inputs\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    train_gen,  # Make sure train_gen yields (encoder_input, decoder_input, mask), decoder_target\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=1,\n",
        "    validation_data=val_gen,  # Make sure val_gen yields (encoder_input, decoder_input, mask), decoder_target\n",
        "    validation_steps=validation_steps\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "lff6iPBrJpKa",
        "outputId": "497f9415-1684-4122-a598-39659f36122e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The name \"decoder_input\" is used 2 times in the model. All operation names should be unique.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-7d3ce336108a>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Update the model's inputs to include the mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Include mask in inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mDotNotTrackScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_self_setattr_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         (nodes, nodes_by_depth, operations, operations_by_depth) = map_graph(\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/function.py\u001b[0m in \u001b[0;36mmap_graph\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;34mf'The name \"{name}\" is used {all_names.count(name)} '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;34m\"times in the model. All operation names should be unique.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The name \"decoder_input\" is used 2 times in the model. All operation names should be unique."
          ]
        }
      ]
    }
  ]
}